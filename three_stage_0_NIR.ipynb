{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13dae17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai\n",
    "# %pip install numpy\n",
    "import os\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: API_KEY=<api key here>\n"
     ]
    }
   ],
   "source": [
    "# i want to change this to load from a .env file\n",
    "%env API_KEY <api key here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API key: <api key here>\n"
     ]
    }
   ],
   "source": [
    "# using this to mimic argparse for easier copy-pasting\n",
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "# using arg defaults\n",
    "args = Object()\n",
    "args.length_limit = 8\n",
    "args.num_cand = 19\n",
    "args.random_seed = 2023\n",
    "args.api_key = os.getenv(\"API_KEY\")\n",
    "print(\"Using API key: {}\".format(args.api_key))\n",
    "\n",
    "rseed = args.random_seed\n",
    "random.seed(rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def write_json(data, file):\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n"
     ]
    }
   ],
   "source": [
    "data_ml_100k = read_json(\"./ml_100k.json\")\n",
    "\n",
    "# print (data_ml_100k[0][0])\n",
    "# print (data_ml_100k[0][1])\n",
    "# print (len(data_ml_100k))\n",
    "\n",
    "client = OpenAI(api_key=args.api_key)\n",
    "\n",
    "u_item_dict = {}\n",
    "u_item_p = 0\n",
    "for elem in data_ml_100k:\n",
    "    seq_list = elem[0].split(\" | \")\n",
    "    for movie in seq_list:\n",
    "        if movie not in u_item_dict:\n",
    "            u_item_dict[movie] = u_item_p\n",
    "            u_item_p += 1\n",
    "print(len(u_item_dict))\n",
    "u_item_len = len(u_item_dict)\n",
    "\n",
    "user_list = []\n",
    "for i, elem in enumerate(data_ml_100k):\n",
    "    item_hot_list = [0 for ii in range(u_item_len)]\n",
    "    seq_list = elem[0].split(\" | \")\n",
    "    for movie in seq_list:\n",
    "        item_pos = u_item_dict[movie]\n",
    "        item_hot_list[item_pos] = 1\n",
    "    user_list.append(item_hot_list)\n",
    "user_matrix = np.array(user_list)\n",
    "user_matrix_sim = np.dot(user_matrix, user_matrix.transpose())\n",
    "\n",
    "pop_dict = {}\n",
    "for elem in data_ml_100k:\n",
    "    # elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(\" | \")\n",
    "    for movie in seq_list:\n",
    "        if movie not in pop_dict:\n",
    "            pop_dict[movie] = 0\n",
    "        pop_dict[movie] += 1\n",
    "\n",
    "i_item_dict = {}\n",
    "i_item_id_list = []\n",
    "i_item_user_dict = {}\n",
    "i_item_p = 0\n",
    "for i, elem in enumerate(data_ml_100k):\n",
    "    seq_list = elem[0].split(\" | \")\n",
    "    for movie in seq_list:\n",
    "        if movie not in i_item_user_dict:\n",
    "            item_hot_list = [0.0 for ii in range(len(data_ml_100k))]\n",
    "            i_item_user_dict[movie] = item_hot_list\n",
    "            i_item_dict[movie] = i_item_p\n",
    "            i_item_id_list.append(movie)\n",
    "            i_item_p += 1\n",
    "        #         item_pos = item_dict[movie]\n",
    "        i_item_user_dict[movie][i] += 1\n",
    "#     user_list.append(item_hot_list)\n",
    "i_item_s_list = []\n",
    "for item in i_item_id_list:\n",
    "    i_item_s_list.append(i_item_user_dict[item])\n",
    "#     print (sum(item_user_dict[item]))\n",
    "item_matrix = np.array(i_item_s_list)\n",
    "item_matrix_sim = np.dot(item_matrix, item_matrix.transpose())\n",
    "\n",
    "id_list = list(range(0, len(data_ml_100k)))\n",
    "\n",
    "### user filtering\n",
    "def sort_uf_items(target_seq, us, num_u, num_i):\n",
    "    candidate_movies_dict = {}\n",
    "    sorted_us = sorted(list(enumerate(us)), key=lambda x: x[-1], reverse=True)[:num_u]\n",
    "    dvd = sum([e[-1] for e in sorted_us])\n",
    "    for us_i, us_v in sorted_us:\n",
    "        us_w = us_v * 1.0 / dvd\n",
    "        #         print (us_i)\n",
    "        us_elem = data_ml_100k[us_i]\n",
    "        #         print (us_elem[0])\n",
    "        #         assert 1==0\n",
    "        us_seq_list = us_elem[0].split(\" | \")  # +[us_elem[1]]\n",
    "\n",
    "        for us_m in us_seq_list:\n",
    "            #             print (f\"{us_m} not in {target_seq}, {us_m not in target_seq}\")\n",
    "            #             break\n",
    "\n",
    "            if us_m not in target_seq:\n",
    "                if us_m not in candidate_movies_dict:\n",
    "                    candidate_movies_dict[us_m] = 0.0\n",
    "                candidate_movies_dict[us_m] += us_w\n",
    "\n",
    "    #         assert 1==0\n",
    "\n",
    "    candidate_pairs = list(\n",
    "        sorted(candidate_movies_dict.items(), key=lambda x: x[-1], reverse=True)\n",
    "    )\n",
    "    #     print (candidate_pairs)\n",
    "    candidate_items = [e[0] for e in candidate_pairs][:num_i]\n",
    "    return candidate_items\n",
    "\n",
    "### item filtering\n",
    "def soft_if_items(target_seq, num_i, total_i, item_matrix_sim, item_dict):\n",
    "    candidate_movies_dict = {}\n",
    "    for movie in target_seq:\n",
    "        #         print('ttt:',movie)\n",
    "        sorted_is = sorted(\n",
    "            list(enumerate(item_matrix_sim[item_dict[movie]])),\n",
    "            key=lambda x: x[-1],\n",
    "            reverse=True,\n",
    "        )[:num_i]\n",
    "        for is_i, is_v in sorted_is:\n",
    "            s_item = i_item_id_list[is_i]\n",
    "\n",
    "            if s_item not in target_seq:\n",
    "                if s_item not in candidate_movies_dict:\n",
    "                    candidate_movies_dict[s_item] = 0.0\n",
    "                candidate_movies_dict[s_item] += is_v\n",
    "    #             print (item_id_list[is_i], candidate_movies_dict)\n",
    "    candidate_pairs = list(\n",
    "        sorted(candidate_movies_dict.items(), key=lambda x: x[-1], reverse=True)\n",
    "    )\n",
    "    #     print (candidate_pairs)\n",
    "    candidate_items = [e[0] for e in candidate_pairs][:total_i]\n",
    "    #     print (candidate_items)\n",
    "    return candidate_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count/total:15/943=0.015906680805938492\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In order to economize, our initial step is to identify user sequences that exhibit a high probability of obtaining accurate predictions from GPT-3.5 based on their respective candidates. \n",
    "Subsequently, we proceed to utilize the GPT-3.5 API to generate predictions for these promising user sequences.\n",
    "\"\"\"\n",
    "results_data_15 = []\n",
    "length_limit = args.length_limit\n",
    "num_u = 12\n",
    "total_i = args.num_cand\n",
    "count = 0\n",
    "total = 0\n",
    "cand_ids = []\n",
    "for i in id_list[:1000]:\n",
    "    elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(\" | \")\n",
    "\n",
    "    candidate_items = sort_uf_items(\n",
    "        seq_list, user_matrix_sim[i], num_u=num_u, num_i=total_i\n",
    "    )\n",
    "\n",
    "    #     print (elem[-1], '-',seq_list[-1])\n",
    "\n",
    "    if elem[-1] in candidate_items:\n",
    "        #         print ('HIT: 1')\n",
    "        count += 1\n",
    "        cand_ids.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    #         print ('HIT: 0')\n",
    "    total += 1\n",
    "print(f\"count/total:{count}/{total}={count*1.0/total}\")\n",
    "print(\"-----------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT:Pulp Fiction\n",
      "predictions:1. The Godfather - Goodfellas\n",
      "2. Fargo - No Country for Old Men\n",
      "3. Toy Story - Up\n",
      "4. North by Northwest - Rear Window\n",
      "5. Star Wars - The Empire Strikes Back\n",
      "6. The Godfather - The Departed\n",
      "7. Fargo - Burn After Reading\n",
      "8. Toy Story - The Incredibles\n",
      "9. North by Northwest - Dial M for Murder\n",
      "10. Star Wars - Raiders of the Lost Ark\n",
      "PID:186; count/total:0/1=0.0\n",
      "\n",
      "GT:Murder at 1600\n",
      "predictions:1. Lost Highway - Mulholland Drive\n",
      "2. Everyone Says I Love You - The Wedding Singer\n",
      "3. Mother - The Babadook\n",
      "4. Love Jones - Brown Sugar\n",
      "5. The Edge - The Grey\n",
      "6. Scream - I Know What You Did Last Summer\n",
      "7. The English Patient - The Remains of the Day\n",
      "8. Conspiracy Theory - The Bourne Identity\n",
      "9. Murder at 1600 - The Pelican Brief\n",
      "10. Murder at 1600 - Absolute Power\n",
      "PID:237; count/total:1/2=0.5\n",
      "\n",
      "GT:Sleepless in Seattle\n",
      "predictions:1. Up Close and Personal - The Devil Wears Prada\n",
      "2. Speed - The Bourne Identity\n",
      "3. To Die For - Gone Girl\n",
      "4. What's Eating Gilbert Grape - Little Miss Sunshine\n",
      "5. Now and Then - The Sisterhood of the Traveling Pants\n",
      "6. Nell - Room\n",
      "7. The Firm - Erin Brockovich\n",
      "8. The Parent Trap - The Princess Diaries\n",
      "9. Sleepless in Seattle - You've Got Mail\n",
      "10. Sleepless in Seattle - When Harry Met Sally\n",
      "PID:357; count/total:2/3=0.6666666666666666\n",
      "\n",
      "GT:Fargo\n",
      "predictions:1. The Celluloid Closet - Milk\n",
      "2. Richard III - Shakespeare in Love\n",
      "3. Star Wars - Guardians of the Galaxy\n",
      "4. Primal Fear - The Silence of the Lambs\n",
      "5. Leaving Las Vegas - Requiem for a Dream\n",
      "6. Everyone Says I Love You - Love Actually\n",
      "7. The English Patient - Atonement\n",
      "8. Fargo - No Country for Old Men\n",
      "9. The Convent - The Witch\n",
      "10. The Convent - The Nun.\n",
      "PID:406; count/total:3/4=0.75\n",
      "\n",
      "GT:Jerry Maguire\n",
      "predictions:1. Crash - Mystic River\n",
      "2. Scream - Halloween\n",
      "3. The Game - The Prestige\n",
      "4. The Devil's Own - The Departed\n",
      "5. Crash - Babel\n",
      "6. Scream - A Nightmare on Elm Street\n",
      "7. The Game - Inception\n",
      "8. The Devil's Own - The Bourne Identity\n",
      "9. Crash - Traffic\n",
      "10. Scream - Friday the 13th\n",
      "PID:427; count/total:3/5=0.6\n",
      "\n",
      "GT:Star Wars\n",
      "predictions:1. Reservoir Dogs - Pulp Fiction\n",
      "2. Full Metal Jacket - Saving Private Ryan\n",
      "3. Rear Window - Vertigo\n",
      "4. The Manchurian Candidate - The Bourne Identity\n",
      "5. Apollo 13 - Gravity\n",
      "6. Harold and Maude - Little Miss Sunshine\n",
      "7. Dead Man Walking - The Green Mile\n",
      "8. Raising Arizona - Fargo\n",
      "9. Star Wars - The Matrix\n",
      "10. Star Wars - Guardians of the Galaxy\n",
      "PID:435; count/total:4/6=0.6666666666666666\n",
      "\n",
      "GT:The Silence of the Lambs\n",
      "predictions:1. The Empire Strikes Back - Star Wars\n",
      "2. Vertigo - Rear Window\n",
      "3. Toy Story - Finding Nemo\n",
      "4. The Godfather - Goodfellas\n",
      "5. Star Wars - Raiders of the Lost Ark\n",
      "6. Lost Highway - Mulholland Drive\n",
      "7. The English Patient - Atonement\n",
      "8. The Silence of the Lambs - Seven\n",
      "9. The Silence of the Lambs - Zodiac\n",
      "10. The Silence of the Lambs - Psycho\n",
      "PID:471; count/total:5/7=0.7142857142857143\n",
      "\n",
      "GT:Courage Under Fire\n",
      "predictions:1. The Rock - Die Hard\n",
      "2. The Godfather - Goodfellas\n",
      "3. Broken Arrow - Mission: Impossible\n",
      "4. Heaven's Prisoners - Mystic River\n",
      "5. The Funeral - A Simple Plan\n",
      "6. The Rock - Con Air\n",
      "7. The Godfather - The Departed\n",
      "8. Broken Arrow - Face/Off\n",
      "9. Heaven's Prisoners - Gone Baby Gone\n",
      "10. The Funeral - The Usual Suspects\n",
      "PID:513; count/total:5/8=0.625\n",
      "\n",
      "GT:Ghost\n",
      "predictions:1. When Harry Met Sally... - Sleepless in Seattle\n",
      "2. The American President - The Proposal\n",
      "3. Don Juan DeMarco - Silver Linings Playbook\n",
      "4. Grease - Dirty Dancing\n",
      "5. The Bridges of Madison County - The Notebook\n",
      "6. The Graduate - 500 Days of Summer\n",
      "7. Titanic - A Walk to Remember\n",
      "8. When Harry Met Sally... - You've Got Mail\n",
      "9. The American President - Notting Hill\n",
      "10. Don Juan DeMarco - Crazy Stupid Love\n",
      "PID:675; count/total:5/9=0.5555555555555556\n",
      "\n",
      "GT:Wag the Dog\n",
      "predictions:1. Good Will Hunting - Dead Poets Society\n",
      "2. Amistad - 12 Years a Slave\n",
      "3. The English Patient - Schindler's List\n",
      "4. Deconstructing Harry - Annie Hall\n",
      "5. Legal Deceit - A Few Good Men\n",
      "6. Good Will Hunting - A Beautiful Mind\n",
      "7. Amistad - Lincoln\n",
      "8. The English Patient - The Reader\n",
      "9. Deconstructing Harry - Crimes and Misdemeanors\n",
      "10. Legal Deceit - Erin Brockovich\n",
      "PID:739; count/total:5/10=0.5\n",
      "\n",
      "GT:The Lion King\n",
      "predictions:1. Fantasia - The Lion King\n",
      "2. The Jungle Book - The Lion King\n",
      "3. Aladdin - The Lion King\n",
      "4. Pinocchio - The Lion King\n",
      "5. Cinderella - The Lion King\n",
      "6. That Darn Cat! - The Lion King\n",
      "7. Fantasia - The Little Mermaid\n",
      "8. The Jungle Book - Beauty and the Beast\n",
      "9. Aladdin - Mulan\n",
      "10. Pinocchio - Snow White and the Seven Dwarfs\n",
      "PID:763; count/total:6/11=0.5454545454545454\n",
      "\n",
      "GT:Waterworld\n",
      "predictions:1. GoodFellas - The Godfather\n",
      "2. The Good, The Bad and The Ugly - A Fistful of Dollars\n",
      "3. Ben-Hur - Gladiator\n",
      "4. Conan the Barbarian - 300\n",
      "5. Butch Cassidy and the Sundance Kid - The Wild Bunch\n",
      "6. Under Siege - Die Hard\n",
      "7. The Magnificent Seven - The Seven Samurai\n",
      "8. Highlander - Braveheart\n",
      "9. Waterworld - Mad Max: Fury Road\n",
      "10. Waterworld - The Road Warrior\n",
      "PID:875; count/total:7/12=0.5833333333333334\n",
      "\n",
      "GT:Star Trek: First Contact\n",
      "predictions:1. Terminator 2: Judgment Day - Star Trek: First Contact\n",
      "2. Star Trek: The Motion Picture - Star Trek: The Wrath of Khan\n",
      "3. Star Trek Generations - Star Trek: Insurrection\n",
      "4. Star Trek V: The Final Frontier - Star Trek: Nemesis\n",
      "5. Star Trek VI: The Undiscovered Country - Star Trek: Beyond\n",
      "6. Star Trek: The Wrath of Khan - Star Trek: Into Darkness\n",
      "7. Star Trek III: The Search for Spock - Star Trek IV: The Voyage Home\n",
      "8. Groundhog Day - Edge of Tomorrow\n",
      "9. Terminator 2: Judgment Day - The Matrix\n",
      "10. Star Trek: The Motion Picture - 2001: A Space Odyssey\n",
      "PID:890; count/total:8/13=0.6153846153846154\n",
      "\n",
      "GT:The Silence of the Lambs\n",
      "predictions:1. The Shawshank Redemption - The Silence of the Lambs\n",
      "2. Taxi Driver - The Silence of the Lambs\n",
      "3. Pulp Fiction - The Silence of the Lambs\n",
      "4. Twelve Monkeys - The Silence of the Lambs\n",
      "5. Clockwork Orange - The Silence of the Lambs\n",
      "6. A - The Silence of the Lambs\n",
      "7. Clerks - The Silence of the Lambs\n",
      "8. Mallrats - The Silence of the Lambs\n",
      "9. Fight Club - The Silence of the Lambs\n",
      "10. American Psycho - The Silence of the Lambs\n",
      "PID:895; count/total:9/14=0.6428571428571429\n",
      "\n",
      "GT:Liar Liar\n",
      "predictions:1. Seven Years in Tibet - The Last Samurai\n",
      "2. Murder at 1600 - The Pelican Brief\n",
      "3. The Edge - The Revenant\n",
      "4. Volcano - Dante's Peak\n",
      "5. G.I. Jane - Zero Dark Thirty\n",
      "6. Titanic - Pearl Harbor\n",
      "7. Air Force One - Olympus Has Fallen\n",
      "8. Scream - I Know What You Did Last Summer\n",
      "9. Seven Years in Tibet - Schindler's List\n",
      "10. Murder at 1600 - Clear and Present Danger\n",
      "PID:911; count/total:9/15=0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_1 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "temp_2 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: {}.\n",
    "Step 2: Selecting the most featured movies from the watched movies according to my preferences (Format: [no. a watched movie.]). \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "temp_3 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: {}.\n",
    "Step 2: Selecting the most featured movies (at most 5 movies) from the watched movies according to my preferences in descending order (Format: [no. a watched movie.]). \n",
    "Answer: {}.\n",
    "Step 3: Can you recommend 10 movies from the Candidate Set similar to the selected movies I've watched (Format: [no. a watched movie - a candidate movie])?.\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "model = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "results_data = []\n",
    "for i in cand_ids[:]:  # [:10] + cand_ids[49:57] + cand_ids[75:81]:\n",
    "    elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(\" | \")[::-1]\n",
    "\n",
    "    candidate_items = sort_uf_items(\n",
    "        seq_list, user_matrix_sim[i], num_u=num_u, num_i=total_i\n",
    "    )\n",
    "    random.shuffle(candidate_items)\n",
    "\n",
    "    input_1 = temp_1.format(\n",
    "        \", \".join(candidate_items), \", \".join(seq_list[-length_limit:])\n",
    "    )\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=model,\n",
    "                prompt=input_1,\n",
    "                max_tokens=512,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                n=1,\n",
    "            )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            # if \"exceeded your current quota\" in str(e):\n",
    "            # open_ai_keys_index +=1\n",
    "            time.sleep(1)\n",
    "            try_nums = try_nums - 1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5)\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=input_1,\n",
    "            max_tokens=256,\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            n=1,\n",
    "        )\n",
    "\n",
    "    predictions_1 = response.choices[0].text\n",
    "\n",
    "    input_2 = temp_2.format(\n",
    "        \", \".join(candidate_items), \", \".join(seq_list[-length_limit:]), predictions_1\n",
    "    )\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=model,\n",
    "                prompt=input_2,\n",
    "                max_tokens=512,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                n=1,\n",
    "            )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            time.sleep(1)\n",
    "            try_nums = try_nums - 1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5)\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=input_2,\n",
    "            max_tokens=256,\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            n=1,\n",
    "        )\n",
    "\n",
    "    predictions_2 = response.choices[0].text\n",
    "\n",
    "    input_3 = temp_3.format(\n",
    "        \", \".join(candidate_items),\n",
    "        \", \".join(seq_list[-length_limit:]),\n",
    "        predictions_1,\n",
    "        predictions_2,\n",
    "    )\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=model,\n",
    "                prompt=input_3,\n",
    "                max_tokens=512,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                n=1,\n",
    "            )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            time.sleep(1)\n",
    "            try_nums = try_nums - 1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5)\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=input_3,\n",
    "            max_tokens=256,\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            n=1,\n",
    "        )\n",
    "\n",
    "    predictions = response.choices[0].text\n",
    "\n",
    "    hit_ = 0\n",
    "    if elem[1] in predictions:\n",
    "        count += 1\n",
    "        hit_ = 1\n",
    "    else:\n",
    "        pass\n",
    "    total += 1\n",
    "\n",
    "    # print (f\"input_1:{input_1}\")\n",
    "    # print (f\"predictions_1:{predictions_1}\\n\")\n",
    "    # print (f\"input_2:{input_2}\")\n",
    "    # print (f\"predictions_2:{predictions_2}\\n\")\n",
    "    # print (f\"input_3:{input_3}\")\n",
    "    print(f\"GT:{elem[1]}\")\n",
    "    print(f\"predictions:{predictions}\")\n",
    "\n",
    "    # print (f\"GT:{elem[-1]}\")\n",
    "    print(f\"PID:{i}; count/total:{count}/{total}={count*1.0/total}\\n\")\n",
    "    result_json = {\n",
    "        \"PID\": i,\n",
    "        \"Input_1\": input_1,\n",
    "        \"Input_2\": input_2,\n",
    "        \"Input_3\": input_3,\n",
    "        \"GT\": elem[1],\n",
    "        \"Predictions_1\": predictions_1,\n",
    "        \"Predictions_2\": predictions_2,\n",
    "        \"Predictions\": predictions,\n",
    "        \"Hit\": hit_,\n",
    "        \"Count\": count,\n",
    "        \"Current_total\": total,\n",
    "        \"Hit@10\": count * 1.0 / total,\n",
    "    }\n",
    "    results_data.append(result_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = (\n",
    "    f\"./results_multi_prompting_len{length_limit}_numcand_{total_i}_seed{rseed}.json\"\n",
    ")\n",
    "write_json(results_data, file_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
